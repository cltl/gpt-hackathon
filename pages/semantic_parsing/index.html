<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/gpt-hackaton/css/franklin.css"> <link rel=stylesheet  href="/gpt-hackaton/css/jemdoc.css"> <link rel=icon  href="/gpt-hackaton/assets/favicon.png"> <title>Structural generalization in semantic parsing</title> <main class=outside > <div class=box > <aside class=layout-menu > <div class=menu-category >introduction</div> <div class="menu-item "><a href="/gpt-hackaton/">Introduction</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/schedule/">Info and schedule</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/contributing/">Contributing</a></div> <div class=menu-category >topics</div> <div class="menu-item "><a href="/gpt-hackaton/pages/consistency_verifiability/">Consistency and Verifiability</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/uncertainty_confidence/">Uncertainty and Confidence</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/framenet/">Framenet</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/historic_dutch/">Historic Dutch</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/medical_notes/">Medical notes</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/toxic_language/">Toxic language</a></div> <div class="menu-item current"><a href="/gpt-hackaton/pages/semantic_parsing/">Semantic parsing</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/biographical_facts/">Biographical Facts</a></div> <div class=menu-category >resources</div> <div class="menu-item "><a href="/gpt-hackaton/pages/references/">References</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/tutorials/">Tutorials/Courses</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/running_llama/">Running LLMs Locally</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/tools/">Tools</a></div> </aside> <div class=layout-content > <div class=franklin-content ><h1 id=structural_generalization_in_semantic_parsing ><a href="#structural_generalization_in_semantic_parsing" class=header-anchor >Structural generalization in semantic parsing</a></h1> <p>See Google Drive Folder for materials and additional explanation: <a href="https://drive.google.com/drive/folders/1D_Glq-6y9L2bwmznGSRVevZx5nBbStwK?usp&#61;share_link">Folder</a></p> <p>Please do not distribute materials beyond this hackathon, as this is work in progress to potentially be published. Thank you&#33; </p> <h2 id=objective ><a href="#objective" class=header-anchor >Objective</a></h2> <p>Prompt engineering to test the structural generalization abilities of GPT-x models with a semantic representation. </p> <h2 id=background_research_question ><a href="#background_research_question" class=header-anchor >Background &amp; Research Question</a></h2> <p>Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. Compositionality helps explain why humans can produce and understand linguistic expressions they have never encountered. The question we investigate with this task is: <strong>can language models generalize in the same ways as humans?</strong> </p> <p><a href="https://aclanthology.org/2020.emnlp-main.731/">COGS: A Compositional Generalization Challenge Based on Semantic Interpretation</a> &#40;Kim &amp; Linzen, 2020&#41; introduced a semantic parsing dataset based on a fragment of English to evaluate the compositional abilities of language processing architectures. The dataset distinguishes two types of generalization &#40;Figure 3 in COGS paper&#41;: </p> <p>&#40;i&#41; <strong><em>Lexical generalization</em></strong> involves recombining known grammatical structures with words that were not observed in these particular structures in training. For example, “object to subject” generalization tests how well a model that only sees a common noun &#40;e.g. “hedgehog”&#41; in object position at training can interpret that noun in subject position at test time.</p> <p>&#40;ii&#41; <strong><em>Structural generalization</em></strong> involves generalizing to linguistic structures that were not seen in training, or combining two novel structures to form a new structure. An example is “PP recursion”, where training instances contain prepositional phrases of depth up to two, and generalization instances have PPs of depth 3–12. </p> <p>Semantic parsers have been shown to struggle primarily with structural generalization tasks unless they have explicit representations of structure &#40;<a href="https://aclanthology.org/2022.emnlp-main.337/">Yao &amp; Koller, 2022</a>&#41;. Large language models additionally show a performance ceiling of 80-90&#37; exact match &#40;<a href="https://aclanthology.org/2022.emnlp-main.624.pdf">Qiu et al., 2022</a>&#41;, which hints that the cases they struggle with are also structural and not lexical. </p> <h2 id=task_description ><a href="#task_description" class=header-anchor >Task Description</a></h2> <p>Develop and tune prompts to test the structural generalization abilities of GPT-x models via semantic parsing. </p> <p>See <strong>Prompting Tips &amp; Tricks</strong> document in Google Drive for an outline of methods to do this, as well as Jupyter notebooks with examples&#33;</p> <h2 id=dataset ><a href="#dataset" class=header-anchor >Dataset </a></h2> <p>A yet-to-be-released dataset &#40;dubbed &#39;SLOG&#39;&#41; will be provided to those working on this task. SLOG extends the <a href="https://github.com/najoungkim/COGS">COGS</a> dataset and introduces new structural generalization cases of &#40;long-distance&#41; extraction and recursion.</p> <p>Find data in <strong>Google Drive Folder</strong> &#40;linked at top&#41;.</p> <p>The dataset contains natural English sentences and their mappings to COGS logical form, as well as splits for training and generalization on several categories of structural generalization. Participants will need to select specific generalization types to focus on.</p> <h3 id=example_input_output ><a href="#example_input_output" class=header-anchor >Example Input &amp; Output</a></h3> <p>Include COGS logical form &#40;see Figure 1 of COGS paper&#41;:</p> <p><strong><em>Example input/prompt</em></strong>: &quot;Provide the correct mapping of the following sentence &#40;<em>taken from gen set</em>&#41; based on this/these example&#40;s&#41; &#40;<em>taken from train set</em>&#41;... Feel free to produce an output more complex than anything you have output before&#33;&quot;</p> <p><strong><em>Example output</em></strong>: English sentence with mapping to COGS LF.</p> <h3 id=evaluation ><a href="#evaluation" class=header-anchor >Evaluation</a></h3> <p>Exact match accuracy on generalization sets. Existing semantic parser performance for reference: <a href="https://docs.google.com/presentation/d/1vJ_VBitlqG9PUS7bYGL442i--PwA9-euRcJjzW4aVy4/edit?usp&#61;sharing">slide 7</a> </p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> CLTL. Last modified: May 04, 2023. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </main>