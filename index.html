<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/gpt-hackaton/css/franklin.css"> <link rel=stylesheet  href="/gpt-hackaton/css/jemdoc.css"> <link rel=icon  href="/gpt-hackaton/assets/favicon.png"> <title>GPT Hackathon</title> <main class=outside > <div class=box > <aside class=layout-menu > <div class=menu-category >introduction</div> <div class="menu-item current"><a href="/gpt-hackaton/">Introduction</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/schedule/">Info and schedule</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/contributing/">Contributing</a></div> <div class=menu-category >topics</div> <div class="menu-item "><a href="/gpt-hackaton/pages/consistency_verifiability/">Consistency and Verifiability</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/uncertainty_confidence/">Uncertainty and Confidence</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/framenet/">Framenet</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/historic_dutch/">Historic Dutch</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/medical_notes/">Medical notes</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/toxic_language/">Toxic language</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/semantic_parsing/">Semantic parsing</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/biographical_facts/">Biographical Facts</a></div> <div class=menu-category >resources</div> <div class="menu-item "><a href="/gpt-hackaton/pages/references/">References</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/tutorials/">Tutorials/Courses</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/running_llama/">Running LLMs Locally</a></div> <div class="menu-item "><a href="/gpt-hackaton/pages/tools/">Tools</a></div> </aside> <div class=layout-content > <div class=franklin-content ><h1 id=hallucination_and_bias_fight_or_exploit ><a href="#hallucination_and_bias_fight_or_exploit" class=header-anchor >Hallucination and bias: fight or exploit?</a></h1> <p>With the release of ChatGPT, the power of and debate around language models have reached the wider public discourse. Even though Large Language Models have been present within the field of NLP for a couple of years now, ChatGPT has raised questions about the role of LLMs in our research. </p> <p>LLMs produce highly fluent and natural-sounding text, which indicates that they have a good representation of many linguistic regularities. At the same time, it is a well-known tendency that they can make up facts and produce entirely nonsensical output with a high degree of confidence and express it in persuasive language &#40;<em>hallucination</em>&#41;. In addition, LLMs are likely to reflect social biases present in their training data. </p> <p>In this hackathon, we want to examine the tension between a high degree of linguistic competence and the danger of hallucination and reproduction of biases. We propose to work on tasks and datasets related to several of our research projects. Some tasks are about understanding text and producing labels &#40;<em>fight</em> hallucination and bias&#41;, while others focus on how we could harness language models to augment datasets &#40;<em>exploit</em> hallucination and bias&#41;. </p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> CLTL. Last modified: May 03, 2023. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </main>